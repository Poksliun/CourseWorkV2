{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from keras import Input\n",
    "from keras import backend as K\n",
    "from keras.layers import Conv2D, MaxPooling2D, Lambda, Flatten, Dense\n",
    "from keras.models import Sequential, save_model, load_model\n",
    "from keras.models import Model\n",
    "from keras.regularizers import l2\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image, ImageFilter\n",
    "\n",
    "from file_handler import handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "image_example = 'resources/proc_data/train_data/false-0.jpg'\n",
    "\n",
    "img_width, img_height = handler.get_image_size(image_example)\n",
    "\n",
    "input_shape = (img_height, img_width, 1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "def image_preparation(img: str) -> np.array:\n",
    "    img = Image.open(img)\n",
    "    gray_img = img.filter(ImageFilter.SMOOTH)\n",
    "    edges_img = gray_img.filter(ImageFilter.FIND_EDGES)\n",
    "    # emboss = edges_img.filter(ImageFilter.EMBOSS)\n",
    "    # edges_img.show()\n",
    "    return np.array(edges_img)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[255, 255, 255, ..., 255, 255, 255],\n       [255,   0,   0, ...,   0,   0, 255],\n       [255,   0,   0, ...,   0,   0, 255],\n       ...,\n       [255,   0,   0, ...,   0,   0, 255],\n       [255,   0,   0, ...,   0,   0, 255],\n       [255, 255, 255, ..., 255, 255, 255]], dtype=uint8)"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_preparation('train/true/true-0.jpg')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "true_img_0 = 'train/true/true-0.jpg'\n",
    "true_img_1 = 'train/true/true-1.jpg'\n",
    "true_img_2 = 'train/true/true-2.jpg'\n",
    "true_img_3 = 'train/true/true-3.jpg'\n",
    "true_img_4 = 'train/true/true-4.jpg'\n",
    "true_img_5 = 'train/true/true-5.jpg'\n",
    "true_img_6 = 'train/true/true-6.jpg'\n",
    "true_img_7 = 'train/true/true-7.jpg'\n",
    "true_img_8 = 'train/true/true-8.jpg'\n",
    "true_img_9 = 'train/true/true-9.jpg'\n",
    "true_img_10 = 'train/true/true-10.jpg'\n",
    "true_img_11 = 'train/true/true-11.jpg'\n",
    "\n",
    "false_img_0 = 'train/false/false-0.jpg'\n",
    "false_img_1 = 'train/false/false-1.jpg'\n",
    "false_img_2 = 'train/false/false-2.jpg'\n",
    "false_img_3 = 'train/false/false-3.jpg'\n",
    "\n",
    "\n",
    "val_img_0 = 'val/true/true-1.jpg'\n",
    "val_img_1 = 'val/true/true-6.jpg'\n",
    "val_img_2 = 'val/true/true-0.jpg'\n",
    "val_img_3 = 'val/false/false-6.jpg'\n",
    "\n",
    "X_train = np.array(\n",
    "    [\n",
    "        [image_preparation(img=true_img_0), image_preparation(img=true_img_1)],\n",
    "        [image_preparation(img=true_img_2), image_preparation(img=false_img_0)],\n",
    "        [image_preparation(img=true_img_4), image_preparation(img=true_img_5)],\n",
    "        [image_preparation(img=true_img_6), image_preparation(img=false_img_2)],\n",
    "        [image_preparation(img=true_img_8), image_preparation(img=true_img_9)],\n",
    "        [image_preparation(img=true_img_10), image_preparation(img=true_img_11)],\n",
    "        [image_preparation(img=true_img_3), image_preparation(img=false_img_1)],\n",
    "        [image_preparation(img=true_img_7), image_preparation(img=false_img_3)]\n",
    "    ]\n",
    ")\n",
    "\n",
    "X_val = np.array([[image_preparation(val_img_0), image_preparation(val_img_1)],[image_preparation(img=val_img_2), image_preparation(img=val_img_3)]])\n",
    "Y_train = np.array((1, 0, 1, 0, 1, 0, 1, 0))\n",
    "Y_val = np.array((1, 0))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "X_train = X_train.reshape((8, 2, 105, 605, 1))\n",
    "X_val = X_val.reshape((2, 2, 105, 605, 1))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "def initialize_weights(shape, dtype=None):\n",
    "  return np.random.normal(loc = 0.0, scale = 1e-2, size = shape)\n",
    "\n",
    "def initialize_bias(shape, dtype=None):\n",
    "  return np.random.normal(loc = 0.5, scale = 1e-2, size = shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "def siamese_nn(input_shape):\n",
    "    \"\"\"\n",
    "        Model architecture\n",
    "    \"\"\"\n",
    "\n",
    "    # Define the tensors for the two input images\n",
    "    left_input = Input(input_shape)\n",
    "    right_input = Input(input_shape)\n",
    "\n",
    "    # Convolutional Neural Network\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(64, (10,10), activation='relu', input_shape=input_shape,\n",
    "                   kernel_initializer=initialize_weights,\n",
    "                   bias_initializer=initialize_bias, kernel_regularizer=l2(2e-4)))\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Conv2D(128, (7,7), activation='relu',\n",
    "                     kernel_initializer=initialize_weights,\n",
    "                     bias_initializer=initialize_bias, kernel_regularizer=l2(2e-4)))\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Conv2D(128, (2,2), activation='relu', kernel_initializer=initialize_weights,\n",
    "                     bias_initializer=initialize_bias, kernel_regularizer=l2(2e-4)))\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Conv2D(256, (2,2), activation='relu', kernel_initializer=initialize_weights,\n",
    "                     bias_initializer=initialize_bias, kernel_regularizer=l2(2e-4)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024, activation='sigmoid',\n",
    "                   kernel_regularizer=l2(2e-3),\n",
    "                   kernel_initializer=initialize_weights,bias_initializer=initialize_bias))\n",
    "\n",
    "    # Generate the encodings (feature vectors) for the two images\n",
    "    encoded_l = model(left_input)\n",
    "    encoded_r = model(right_input)\n",
    "\n",
    "    # Add a customized layer to compute the absolute difference between the encodings\n",
    "    L1_layer = Lambda(lambda tensors:K.abs(tensors[0] - tensors[1]))\n",
    "    L1_distance = L1_layer([encoded_l, encoded_r])\n",
    "\n",
    "    # Add a dense layer with a sigmoid unit to generate the similarity score\n",
    "    prediction = Dense(1,activation='sigmoid',bias_initializer=initialize_bias)(L1_distance)\n",
    "\n",
    "    # Connect the inputs with the outputs\n",
    "    siamese_net = Model(inputs=[left_input,right_input],outputs=prediction)\n",
    "\n",
    "    # return the model\n",
    "    return siamese_net"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_11 (InputLayer)          [(None, 105, 605, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " input_12 (InputLayer)          [(None, 105, 605, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " sequential_5 (Sequential)      (None, 1024)         168116032   ['input_11[0][0]',               \n",
      "                                                                  'input_12[0][0]']               \n",
      "                                                                                                  \n",
      " lambda_3 (Lambda)              (None, 1024)         0           ['sequential_5[0][0]',           \n",
      "                                                                  'sequential_5[1][0]']           \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, 1)            1025        ['lambda_3[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 168,117,057\n",
      "Trainable params: 168,117,057\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/8\n",
      "1/1 [==============================] - 4s 4s/step - loss: 17.6212 - accuracy: 0.5000 - val_loss: 17.5950 - val_accuracy: 0.5000\n",
      "Epoch 2/8\n",
      "1/1 [==============================] - 3s 3s/step - loss: 17.5696 - accuracy: 0.5000 - val_loss: 17.5656 - val_accuracy: 0.5000\n",
      "Epoch 3/8\n",
      "1/1 [==============================] - 3s 3s/step - loss: 17.5212 - accuracy: 0.6250 - val_loss: 17.5380 - val_accuracy: 0.5000\n",
      "Epoch 4/8\n",
      "1/1 [==============================] - 3s 3s/step - loss: 17.4773 - accuracy: 0.8750 - val_loss: 17.5121 - val_accuracy: 0.5000\n",
      "Epoch 5/8\n",
      "1/1 [==============================] - 3s 3s/step - loss: 17.4369 - accuracy: 1.0000 - val_loss: 17.4873 - val_accuracy: 1.0000\n",
      "Epoch 6/8\n",
      "1/1 [==============================] - 3s 3s/step - loss: 17.3982 - accuracy: 1.0000 - val_loss: 17.4626 - val_accuracy: 1.0000\n",
      "Epoch 7/8\n",
      "1/1 [==============================] - 3s 3s/step - loss: 17.3602 - accuracy: 1.0000 - val_loss: 17.4374 - val_accuracy: 1.0000\n",
      "Epoch 8/8\n",
      "1/1 [==============================] - 3s 3s/step - loss: 17.3229 - accuracy: 1.0000 - val_loss: 17.4118 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "model = siamese_nn(input_shape)\n",
    "model.summary()\n",
    "optimizer = Adam(learning_rate=0.00001)\n",
    "model.compile(loss=['poisson'], optimizer=optimizer, metrics=['accuracy'])\n",
    "history_cnn = model.fit(\n",
    "    [X_train[:,0], X_train[:,1]],\n",
    "    Y_train,\n",
    "    batch_size=16,\n",
    "    epochs=8,\n",
    "    validation_data=([X_val[:,0], X_val[:,1]], Y_val)\n",
    "  )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [
    "test_img_0 = 'train/true/true-0.jpg'\n",
    "test_img_1 = 'train/true/true-8.jpg'\n",
    "test_img_2 = 'val/true/true-0.jpg'\n",
    "test_img_3 = 'test/false/false-0.jpg'\n",
    "x_test = np.array([[image_preparation(test_img_0), image_preparation(test_img_2)]]).reshape((1, 2, 105, 605, 1))\n",
    "y_test = np.array([0])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 85ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([[0.522997]], dtype=float32)"
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([x_test[:,0],x_test[:,1]])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 109ms/step - loss: 17.4066 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": "[17.406583786010742, 0.0]"
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate([x_test[:,0],x_test[:,1]], y_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
